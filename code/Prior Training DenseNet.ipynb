{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a793bc1f-011e-496f-bacf-3ab10055724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from custommodels import LoadDataset, ResNet50, DenseNet121, MobileNetV2\n",
    "from training import ModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caa3db01-8093-4b9e-8d7d-e6026379353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to reproduce\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e75bd4a-a24c-4419-bf22-a1c48ae7800e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Width: 200 Height: 150\n"
     ]
    }
   ],
   "source": [
    "db = \"HAM\"\n",
    "root = f\"../../dataset/CAI 2025/{db}/\"\n",
    "df_train = pd.read_csv(f\"{root}/dataframe/df_distance_train.csv\")\n",
    "df_valid = pd.read_csv(f\"{root}/dataframe/df_distance_valid.csv\")\n",
    "df_test = pd.read_csv(f\"{root}/dataframe/df_distance_test.csv\")\n",
    "\n",
    "loader = LoadDataset(label=\"label\", batch_size=16)\n",
    "train_loader, valid_loader, test_loader = loader.create_dataloaders(df_train, df_valid, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c35d48b-91ae-4ca3-948c-4d63d8dffa53",
   "metadata": {},
   "source": [
    "# DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d41a4072-154a-41ef-b317-54a55979741e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../dataset/CAI 2025/HAM/model/DENSE/ created.\n"
     ]
    }
   ],
   "source": [
    "models = [\"RES\", \"DENSE\", \"MOBILE\"]\n",
    "\n",
    "model_save_directory = f\"{root}model/{models[1]}/\"\n",
    "if not os.path.exists(model_save_directory):\n",
    "    os.makedirs(model_save_directory)\n",
    "    print(f\"{model_save_directory} created.\")\n",
    "else:\n",
    "    print(f\"{model_save_directory} aready exist.\")\n",
    "        \n",
    "df_valid_filepath = f\"{root}dataframe/df_valid_{models[1]}.csv\"\n",
    "df_test_filepath = f\"{root}dataframe/df_test_{models[1]}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "253c5061-808b-4175-9bab-7b49955b1d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: torch.Size([16, 8])\n",
      "Outputs: tensor([[ 0.6103, -0.0879, -0.2834, -0.3834,  1.2911, -0.5435, -0.1924,  0.0657],\n",
      "        [ 0.2813, -0.3094, -0.6580,  0.2825,  0.4217, -0.6519,  0.0356, -0.4843],\n",
      "        [-0.1475, -1.0301,  0.2355, -0.3393,  1.1840, -0.3170, -1.3201,  0.6693],\n",
      "        [ 0.4064, -0.1580, -0.6222, -0.2738,  0.8584, -0.2091,  0.1552, -0.1299],\n",
      "        [-0.0466, -0.1066, -0.3220,  0.1892,  0.5468, -0.2143,  0.0230,  0.6249],\n",
      "        [ 0.5081, -0.1314, -0.3043,  0.2236,  0.0990, -0.0171, -0.6231,  0.4407],\n",
      "        [ 0.0765, -0.5912, -0.5073,  0.1639,  0.3920, -0.1186,  0.1073, -0.3738],\n",
      "        [-0.0264,  0.2046, -0.3678,  0.1322,  0.5219, -0.3537, -0.3272, -0.1436],\n",
      "        [ 0.1615, -0.7940, -0.5219,  0.2894,  1.3402, -0.4593, -0.5330, -0.3476],\n",
      "        [ 0.6707, -0.4145,  0.3201, -0.4594,  0.7444, -0.6188, -0.8979, -0.0272],\n",
      "        [ 0.2084,  0.2695, -0.1218,  0.1832,  0.7997, -0.2916, -0.0970,  0.0632],\n",
      "        [ 0.7139, -0.0310,  0.3488, -0.6736,  0.6798, -0.1778, -0.5499,  0.0592],\n",
      "        [ 0.1474,  0.0688,  0.0549,  0.3571,  1.1247, -0.2989, -0.7470, -0.4275],\n",
      "        [ 0.6393, -0.7482, -0.8199, -0.7107,  0.2764, -0.5647, -0.7569,  0.3257],\n",
      "        [-0.0544, -0.4551, -0.6593, -0.1420,  0.7911, -0.7794, -0.0155,  0.3524],\n",
      "        [ 0.1052, -0.1001, -0.2829, -0.1321,  0.8236, -0.4528, -0.2294,  0.1619]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "Labels shape: torch.Size([16])\n",
      "Labels: tensor([0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m DenseNet121(num_class)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m ModelTrainer()\n\u001b[0;32m----> 8\u001b[0m best_val_file \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtrain(model, train_loader, valid_loader, model_save_directory, num_epochs\u001b[38;5;241m=\u001b[39mnum_epochs, lr\u001b[38;5;241m=\u001b[39mlr)\n",
      "File \u001b[0;32m~/notebooks/IEEE CAI 2025/training.py:47\u001b[0m, in \u001b[0;36mModelTrainer.train\u001b[0;34m(self, model, train_loader, valid_loader, model_save_directory, num_epochs, lr, weight_decay)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabels:\u001b[39m\u001b[38;5;124m\"\u001b[39m, labels)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#print(\"Labels dtype:\", labels.dtype)\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     48\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# 偏微分の実行。評価のときは実行しない。\u001b[39;00m\n\u001b[1;32m     49\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# 偏微分に基づいて実際に移動する。評価のときは移動しない。評価のときは学習しないから。\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/loss.py:1185\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m-> 1185\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mcross_entropy(\u001b[38;5;28minput\u001b[39m, target, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[1;32m   1186\u001b[0m                            ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction,\n\u001b[1;32m   1187\u001b[0m                            label_smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_smoothing)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:3086\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3085\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3086\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mcross_entropy_loss(\u001b[38;5;28minput\u001b[39m, target, weight, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"nll_loss_forward_reduce_cuda_kernel_2d_index\" not implemented for 'Float'"
     ]
    }
   ],
   "source": [
    "num_class = 8\n",
    "num_epochs = 30\n",
    "lr = 1e-6\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DenseNet121(num_class).to(device)\n",
    "trainer = ModelTrainer()\n",
    "best_val_file = trainer.train(model, train_loader, valid_loader, model_save_directory, num_epochs=num_epochs, lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281b5347-b9a4-48e5-a200-983091c25d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(num_class).to(device)\n",
    "model.load_state_dict(torch.load(best_val_file))\n",
    "test_predictions, test_outputs = trainer.evaluate(model, valid_loader)\n",
    "df_valid[\"pred\"] = test_predictions\n",
    "df_valid[\"proba\"] = test_outputs\n",
    "df_valid.to_csv(df_valid_filepath, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c86b9f3-658e-476e-a41a-65a60afdfed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions, test_outputs = trainer.evaluate(model, test_loader)\n",
    "df_test[\"pred\"] = test_predictions\n",
    "df_test[\"proba\"] = test_outputs\n",
    "df_test.to_csv(df_valid_filepath, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
